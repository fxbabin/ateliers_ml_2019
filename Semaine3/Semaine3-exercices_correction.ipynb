{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ULwBwfH9-dNH"
   },
   "source": [
    "# Régression linéaire à plusieurs variables - Exercices tirés du MOOC d'Andrew Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Gnvh5p--dNT"
   },
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nehocufk-dNa"
   },
   "source": [
    "Le jeu de données donne la valeur de plusieurs maisons, ainsi que leur taille (pieds carrés) et le nombre de chambres à coucher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yusgFG3V-dNp"
   },
   "source": [
    "### Chargez les données du fichier ex1data1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVIWwAO9-dNy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40WxZntB-dOn"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXflvRX4-dO-"
   },
   "source": [
    "### Visualisez les données (valeurs réelles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dP-fVrLz-dPD"
   },
   "source": [
    "Maintenant, nous avons deux 'features'. Voyez si elles ont le même ordre de grandeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUq9WWRh-dPG",
    "outputId": "8703099c-b463-4536-8d42-8197a0a14b1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>nb_bedrooms</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2104</td>\n",
       "      <td>3</td>\n",
       "      <td>399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1416</td>\n",
       "      <td>2</td>\n",
       "      <td>232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>539900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1985</td>\n",
       "      <td>4</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1534</td>\n",
       "      <td>3</td>\n",
       "      <td>314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1427</td>\n",
       "      <td>3</td>\n",
       "      <td>198999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1380</td>\n",
       "      <td>3</td>\n",
       "      <td>212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1494</td>\n",
       "      <td>3</td>\n",
       "      <td>242500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1940</td>\n",
       "      <td>4</td>\n",
       "      <td>239999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1890</td>\n",
       "      <td>3</td>\n",
       "      <td>329999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4478</td>\n",
       "      <td>5</td>\n",
       "      <td>699900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1268</td>\n",
       "      <td>3</td>\n",
       "      <td>259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2300</td>\n",
       "      <td>4</td>\n",
       "      <td>449900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1320</td>\n",
       "      <td>2</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1236</td>\n",
       "      <td>3</td>\n",
       "      <td>199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2609</td>\n",
       "      <td>4</td>\n",
       "      <td>499998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3031</td>\n",
       "      <td>4</td>\n",
       "      <td>599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1767</td>\n",
       "      <td>3</td>\n",
       "      <td>252900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1888</td>\n",
       "      <td>2</td>\n",
       "      <td>255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1604</td>\n",
       "      <td>3</td>\n",
       "      <td>242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1962</td>\n",
       "      <td>4</td>\n",
       "      <td>259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3890</td>\n",
       "      <td>3</td>\n",
       "      <td>573900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1458</td>\n",
       "      <td>3</td>\n",
       "      <td>464500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2526</td>\n",
       "      <td>3</td>\n",
       "      <td>469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2200</td>\n",
       "      <td>3</td>\n",
       "      <td>475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2637</td>\n",
       "      <td>3</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1839</td>\n",
       "      <td>2</td>\n",
       "      <td>349900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>169900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2040</td>\n",
       "      <td>4</td>\n",
       "      <td>314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3137</td>\n",
       "      <td>3</td>\n",
       "      <td>579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1811</td>\n",
       "      <td>4</td>\n",
       "      <td>285900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1239</td>\n",
       "      <td>3</td>\n",
       "      <td>229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2132</td>\n",
       "      <td>4</td>\n",
       "      <td>345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4215</td>\n",
       "      <td>4</td>\n",
       "      <td>549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2162</td>\n",
       "      <td>4</td>\n",
       "      <td>287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1664</td>\n",
       "      <td>2</td>\n",
       "      <td>368500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2238</td>\n",
       "      <td>3</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2567</td>\n",
       "      <td>4</td>\n",
       "      <td>314000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1200</td>\n",
       "      <td>3</td>\n",
       "      <td>299000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>852</td>\n",
       "      <td>2</td>\n",
       "      <td>179900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1852</td>\n",
       "      <td>4</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1203</td>\n",
       "      <td>3</td>\n",
       "      <td>239500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    size  nb_bedrooms   price\n",
       "0   2104            3  399900\n",
       "1   1600            3  329900\n",
       "2   2400            3  369000\n",
       "3   1416            2  232000\n",
       "4   3000            4  539900\n",
       "5   1985            4  299900\n",
       "6   1534            3  314900\n",
       "7   1427            3  198999\n",
       "8   1380            3  212000\n",
       "9   1494            3  242500\n",
       "10  1940            4  239999\n",
       "11  2000            3  347000\n",
       "12  1890            3  329999\n",
       "13  4478            5  699900\n",
       "14  1268            3  259900\n",
       "15  2300            4  449900\n",
       "16  1320            2  299900\n",
       "17  1236            3  199900\n",
       "18  2609            4  499998\n",
       "19  3031            4  599000\n",
       "20  1767            3  252900\n",
       "21  1888            2  255000\n",
       "22  1604            3  242900\n",
       "23  1962            4  259900\n",
       "24  3890            3  573900\n",
       "25  1100            3  249900\n",
       "26  1458            3  464500\n",
       "27  2526            3  469000\n",
       "28  2200            3  475000\n",
       "29  2637            3  299900\n",
       "30  1839            2  349900\n",
       "31  1000            1  169900\n",
       "32  2040            4  314900\n",
       "33  3137            3  579900\n",
       "34  1811            4  285900\n",
       "35  1437            3  249900\n",
       "36  1239            3  229900\n",
       "37  2132            4  345000\n",
       "38  4215            4  549000\n",
       "39  2162            4  287000\n",
       "40  1664            2  368500\n",
       "41  2238            3  329900\n",
       "42  2567            4  314000\n",
       "43  1200            3  299000\n",
       "44   852            2  179900\n",
       "45  1852            4  299900\n",
       "46  1203            3  239500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZPqY0zPr-dPn"
   },
   "source": [
    "## Définissez quelques variables utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oE8AcnWD-dP0"
   },
   "source": [
    "### Définissez X et y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-eyW5vQ3-dP4"
   },
   "source": [
    "X est maintenant une matrice de dimensions m x 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELWluGEU-dP9"
   },
   "outputs": [],
   "source": [
    "X = data.values[:,:2]  #convert dataframe to numpy array\n",
    "y = np.array(data.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-siAc27-dQm"
   },
   "source": [
    "### Initialisez theta (combien de dimensions?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8r-s4Pcf-dQw"
   },
   "outputs": [],
   "source": [
    "theta = np.zeros(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xi5RASKt-dRQ"
   },
   "source": [
    "### Vérifiez les dimensions de theta et de X. Sont-elles compatibles pour implémenter la fonction d'hypothèse sous forme vectorisée?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RXzZ2keY-dRZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (47, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "suwCMnrm-dR1"
   },
   "source": [
    "### Modifiez X en conséquence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ao3dQZTH-dR4"
   },
   "outputs": [],
   "source": [
    "X = np.c_[np.ones(X.shape[0]), X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o68FGIcE-dSB"
   },
   "source": [
    "## Écrivez une fonction pour centrer et réduire les features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XRPy8ek-dSE"
   },
   "outputs": [],
   "source": [
    "def featureNormalize(X):\n",
    "    mean = X.mean(axis=0)\n",
    "    stdev = X.std(axis=0)\n",
    "    X = (X - mean)/stdev\n",
    "    return X, mean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ah4o2NM4-dSU"
   },
   "outputs": [],
   "source": [
    "X[:,1:], mean, stdev = featureNormalize(X[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uFn9YUZt-dSd"
   },
   "source": [
    "### Maintenant nous allons devoir adapter nos fonctions _predict_, _fit_, et _cost_ à une situation à plusieurs variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ThlVQEI-dSg"
   },
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    return(np.dot(X, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-15999395.00, -4970914.27, -2571314.62])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot((predict(X, theta) - y), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecrM6j9K-dSz"
   },
   "outputs": [],
   "source": [
    "def cost(X, y, theta):\n",
    "    return ((1/(2 * X.shape[0])) * (np.sum((predict(X, theta) - y)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCtM37Mk-dTA"
   },
   "outputs": [],
   "source": [
    "def fit_with_cost(X, y, theta, alpha, num_iters):\n",
    "    m = X.shape[0]\n",
    "    J_history = []\n",
    "    for i in range(num_iters):\n",
    "        theta = theta - (alpha/m) * np.dot((predict(X, theta) - y), X)\n",
    "        J_history.append(cost(X, y, theta))\n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivUR2nTo-dTM"
   },
   "source": [
    "## Lancez l'entrainement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iT1WXlWm-dTT"
   },
   "source": [
    "Vous êtes libres de choisir alpha et num_iters cette fois!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABen8SGh-dTY"
   },
   "outputs": [],
   "source": [
    "theta, J_history = fit_with_cost(X, y, theta, 0.01, 3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cNcBTwN-dTm"
   },
   "source": [
    "## Visualisez l'évolution du coût (graphe de convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6CYvorH-dTt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f21aeab19e8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(J_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdxXu7Cj-dT1"
   },
   "source": [
    "## Testez votre modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hcJvXXJM-dT2"
   },
   "source": [
    "Que vaut une maison de 1650 pieds carrés et de 3 chambres à coucher? (Si la valeur est aberrante, vous avez peut-être oublié une étape...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEI0kuWI-dT_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293081.46686103614"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = (np.array([1650,3]) - mean) / stdev\n",
    "X_test = np.hstack([1, X_test])\n",
    "predict(X_test,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6L1TpxI-dUH"
   },
   "source": [
    "### Réécrivez votre fonction fit pour qu'elle prenne en compte un parametre de regularisation (L1, L2 pour Lasso ou Ridge) et adapte la mise  a jour de theta an fonction de la regularization précisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with_regularization(X, y, theta, alpha, num_iters, regularization=\"\", lbda=0.1):\n",
    "    m = X.shape[0]\n",
    "    J_history = []\n",
    "    \n",
    "    reg = 0\n",
    "    if regularization == \"L1\":\n",
    "        reg = (lbda / m) * np.absolute(theta)\n",
    "    elif regularization == \"L2\":\n",
    "        reg = (lbda / m) * np.square(theta)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        theta = theta - (alpha/m) * (np.dot((predict(X, theta) - y), X) + reg)\n",
    "        J_history.append(cost(X, y, theta))  \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#theta = np.zeros(3)\n",
    "theta, J_history = fit_with_regularization(X, y, theta, 0.01, 10000, regularization=\"L2\", lbda=0.001)\n",
    "\n",
    "fit = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(J_history)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = (np.array([1650,3]) - mean) / stdev\n",
    "X_test = np.hstack([1, X_test])\n",
    "predict(X_test,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La fonction fit au complet. Ajoutez un dernier parametre qui précise le gradient employé (stochastic, mini_batch(avec le batch_size), batch). Pour la descente de gradient stochastic et minibatch on met a jour le learning rate avec la formule du learning rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def learning_rate_decay(alpha_0, epochs, decay_rate):\n",
    "    return((1 / (1 + decay_rate * epochs)) * alpha_0)\n",
    "\n",
    "\n",
    "def batch_generator(X, y, batch_size):\n",
    "    np.random.shuffle(X)\n",
    "    size = X.shape[0]\n",
    "    b_size = 0\n",
    "    batches_X = []\n",
    "    batches_y = []\n",
    "    while (b_size + batch_size) < size:\n",
    "        batches_X.append(X[b_size:(b_size + batch_size)])\n",
    "        batches_y.append(y[b_size:(b_size + batch_size)])\n",
    "        b_size += batch_size\n",
    "    batches_X.append(X[b_size:size])\n",
    "    batches_y.append(y[b_size:size])\n",
    "    nb_batches = size // batch_size\n",
    "    while True:\n",
    "        rand_nb = random.randint(0,nb_batches-1)\n",
    "        yield batches_X[rand_nb], batches_y[rand_nb]\n",
    "\n",
    "\n",
    "def complete_fit(X,\n",
    "                 y,\n",
    "                 theta, \n",
    "                 alpha, \n",
    "                 num_iters, \n",
    "                 regularization=\"L1\",\n",
    "                 lbda=0.01,\n",
    "                 gradient_descent=\"batch\",\n",
    "                 batch_size=4,\n",
    "                 decay_rate=0.0):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    J_history = []\n",
    "    alpha_0 = alpha\n",
    "    \n",
    "    batch_s = m\n",
    "    if gradient_descent == \"batch\":\n",
    "        decay_rate = 0.0\n",
    "        batch_s = m \n",
    "    elif gradient_descent == \"mini_batch\":\n",
    "        batch_s = batch_size\n",
    "    elif gradient_descent == \"stochastic\":\n",
    "        batch_s = 1\n",
    "\n",
    "    reg = 0\n",
    "    if regularization == \"L1\":\n",
    "        reg = (lbda / batch_s) * np.absolute(theta)\n",
    "    elif regularization == \"L2\":\n",
    "        reg = (lbda / batch_s) * np.square(theta)\n",
    "        \n",
    "    b_gen = batch_generator(X, y, batch_s)\n",
    "    for epoch in range(num_iters):\n",
    "        X_tmp, y_tmp = next(b_gen)\n",
    "        theta = theta - (alpha/m) * (np.dot((predict(X_tmp, theta) - y_tmp), X_tmp) + reg)\n",
    "        alpha = learning_rate_decay(alpha_0, epoch, decay_rate)\n",
    "        J_history.append(cost(X_tmp, y_tmp, theta))  \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(3)\n",
    "theta, J_history = complete_fit(X, y, theta, 0.01, 200,regularization=\"L1\",\n",
    "                                lbda=0.0, gradient_descent=\"stochastic\", batch_size=16,\n",
    "                                decay_rate=0.01)\n",
    "print(theta)\n",
    "fit = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(J_history)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(3)\n",
    "theta, J_history = complete_fit(X, y, theta, 0.01, 200,regularization=\"L1\",\n",
    "                                lbda=0.0, gradient_descent=\"mini_batch\", batch_size=16,\n",
    "                                decay_rate=0.01)\n",
    "print(theta)\n",
    "fit = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(J_history)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(3)\n",
    "theta, J_history = complete_fit(X, y, theta, 0.01, 200,regularization=\"L1\",\n",
    "                                lbda=0.0, gradient_descent=\"batch\", batch_size=16,\n",
    "                                decay_rate=0.01)\n",
    "print(theta)\n",
    "fit = plt.figure()\n",
    "ax = plt.axes()\n",
    "ax.plot(J_history)\n",
    "print(theta)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Semaine3-exercices.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
